{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2a319c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aggregation by Group\n",
    "*Stats 507, Fall 2021*\n",
    "\n",
    "James Henderson, PhD  \n",
    "September 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0cd8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "  - [Split-Apply-Combine](#/slide-2-0)\n",
    "  - [Categorical data](#/slide-4-0)\n",
    "  - [Pandas .groupby() method](#/slide-5-0)\n",
    "  - [Re-merging](#/slide-6-0)\n",
    "  - [Aggregation Functions](#/slide-7-0)\n",
    "  - [Generalized Split-Apply-Combine with .apply()](#/slide-8-0)\n",
    "  - [Takeaways](#/slide-9-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f968b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split, Apply, Combine\n",
    "  - A common task in data analysis is to compute some summary statistic\n",
    "    (an aggregation) for disjoint subsets (subgroups) in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0431747",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Split, Apply, Combine\n",
    "  - This task is often referred to as *split-apply-combine* b/c we:\n",
    "    + *split* the data into groups,\n",
    "    + *apply* an aggregation function to each group,\n",
    "    +  and then *combine* the results into a new data frame or column(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf54081",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example Data\n",
    "  - Here is a small example dataset we'll use in these slides.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de26532",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "rng = np.random.default_rng(9 * 2021 * 28)\n",
    "n=100\n",
    "a = rng.binomial(n=1, p=0.5, size=n)\n",
    "b = 1 - 0.5 * a + rng.normal(size=n)\n",
    "c = 0.8 * a + rng.normal(size=n) \n",
    "df = pd.DataFrame({'a': a, 'b': b, 'c': c})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ad110",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical Data \n",
    "  - Grouping is most commonly done with categorical data.\n",
    "  - Categorical data are often coded as integers having associated labels.\n",
    "  - Panda's `pd.categorical()` can be used to create a categorical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6da963",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df['a'] = pd.Categorical(df['a'].replace({0: 'control', 1: 'treatment'}))\n",
    "(df['a'].dtype, df['a'].values.categories, df['a'].values.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68072ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas .groupby() method\n",
    "  - The split-apply-combine or *aggregation by group* paradigm is implemented\n",
    "    in pandas as the `.groupby()` method.   \n",
    "  - We'll focus on grouping by variables in the data; you'll read about \n",
    "    other ways of grouping.\n",
    "  - We'll also limit our focus to grouping rows, but columns can be\n",
    "    grouped too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e1aaa",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('a').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c27d00",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas .groupby() method\n",
    "  - By default, the columns used to define group membership become the index\n",
    "    in the resulting DataFrameGroupBy object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2775aa",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "[df.groupby('a').mean().index, df.groupby('a').mean().columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f422a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas .groupby() method\n",
    "  - By default, the columns used to define group membership become the index\n",
    "    in the resulting DataFrameGroupBy object. \n",
    "  - You can request the group keys as value columns using `as_index=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e58041",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('a', as_index=False).mean().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaccbe6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Re-merging\n",
    "  - *Re-merging* is the name for a technique in which aggregation by group is\n",
    "    used to compute summary statistics which are then (re-)merged with the\n",
    "    source data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcaafe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Re-merging\n",
    "  - For example, you may want to compute a mean/min/max by group and then\n",
    "    broadcast to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df8ab8",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df_max_a = (\n",
    "    df\n",
    "    .groupby('a')[['b']]\n",
    "    .max()\n",
    "    .rename(columns={'b': 'b_max'})\n",
    "    )\n",
    "df2 = df.set_index('a').join(df_max_a)\n",
    "df2.groupby(level='a').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed01090",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Indexing \n",
    "  - In the previous example (copied below), note that we indexed the \n",
    "    DataFrameGroupBy object to limit the columns operated on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aaa995",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df_max_a = (\n",
    "    df\n",
    "    .groupby('a')[['b']]\n",
    "    .max()\n",
    "    .rename(columns={'b': 'b_max'})\n",
    "    )\n",
    "df2 = df.set_index('a').join(df_max_a)\n",
    "df2.groupby(level='a').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dfb3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Re-merging\n",
    "  - *Re-merging* is a very general technique.\n",
    "  - In pandas this can also be accomplished using `.groupby()` with \n",
    "   `.transform()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea21e7",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3[['b_max', 'c_max']] = (\n",
    "       df3\n",
    "       .groupby('a')\n",
    "       .transform(np.max)       \n",
    "       )\n",
    "df3.groupby('a').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a801bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aggregation functions\n",
    "  - Common aggregation functions have been optimized for groupby and are\n",
    "    available as methods (see Table 10-1 in McKinney): \n",
    "      + sum, mean, std, var, median,\n",
    "      + min, max, first, last,\n",
    "      + count (compare to size).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce3682",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df3.iloc[1, 1] = np.nan\n",
    "df3.groupby('a').size()\n",
    "#df3.groupby('a').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f80a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Aggregation functions\n",
    "  - The `.agg()` (`.aggregate()`) method supports more general functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d917ea",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    " df\n",
    " .groupby('a')\n",
    " .agg(lambda x: np.quantile(x, .75) - np.quantile(x, .25))\n",
    " .rename(mapper=lambda x: 'iqr_' + x, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e039cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Aggregation functions\n",
    "  - You can use a list or a list of tuples with `.agg()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc75392",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "f_list = [\n",
    "    ('min', np.min),\n",
    "    ('max', np.max),\n",
    "    ('iqr', lambda x: np.quantile(x, .75) - np.quantile(x, .25)),\n",
    "    ]\n",
    "df.groupby('a').agg(f_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093d6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Aggregation functions\n",
    "  - Series methods can also be used with *GroupBy objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb54f5",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('a').quantile((.025, .975))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01220e6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Split-Apply-Combine\n",
    "  - For more general tasks, the `.apply()` method operates on each subset of\n",
    "    data and then puts them back together.\n",
    "  - Useful especially when implementing multi-column logic. \n",
    "  - In this example, we keep all rows where b or c is in the top or bottom 2.5% \n",
    "    within each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47231fd1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Split-Apply-Combine\n",
    "  - Here is a function that implements the desired subset behavior for a \n",
    "    DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95719d5c",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "def tail_values(df, columns=None, lwr=.025, upr=.975):\n",
    "    \"\"\"\n",
    "    Subset a DataFrame df to find rows with values in the distributional tail.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame to be subset.\n",
    "    columns : string or list of strings. Optional.\n",
    "        Names of columns in which to look for tail values. If None use all\n",
    "        columns.  The default is None.\n",
    "    lwr, upr : float. Optional.\n",
    "        Sample quantiles (inclusive) demarking the lower and upper tails,\n",
    "        respectively. The defaults are .025 and .975.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A subset of df with rows taking values in the distributional tail of any\n",
    "    column in columns.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        tail = df.transform(lambda x: (\n",
    "           np.logical_or(x >= np.quantile(x, upr), x <= np.quantile(x, lwr))\n",
    "           )).any(axis=1)\n",
    "    elif isinstance(columns, list):\n",
    "        tail = df[columns].transform(lambda x: (\n",
    "            np.logical_or(x >= np.quantile(x, upr), x <= np.quantile(x, lwr))\n",
    "            )).any(axis=1)\n",
    "    elif isinstance(columns, str):\n",
    "        tail = df[[columns]].transform(lambda x: (\n",
    "            np.logical_or(x >= np.quantile(x, upr), x <= np.quantile(x, lwr))\n",
    "            )).any(axis=1)\n",
    "    else:\n",
    "        raise TypeError(\"columns should be a str, list or None.\")\n",
    "\n",
    "    return(df[tail])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d4153",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Split-Apply-Combine\n",
    "  - And now we apply the function to each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba923a0",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('a').apply(tail_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928fd92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Takeaways 1/2\n",
    "  - *Split-Apply-Combine* or *aggregation by group* is implemented in the \n",
    "    `.groupby()` method of pandas DataFrame (Series) class.\n",
    "  - Grouping variables become an index by default; control with `as_index`.\n",
    "  - Create new columns with group-wise summary statistics using\n",
    "    `.groupby()` and `.transform()` or by re-merging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02637bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaways 2/2\n",
    "  - Use optimized aggregation functions when available and the `.agg()` method\n",
    "    when not.\n",
    "  - For more complex operations, the `.apply()` method operates on each\n",
    "    group and then puts the pieces back together. \n",
    "  - Use this and other DataFrame methods whenever you can. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "rise",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "header": "<a href=\"#/slide-0-0\"> <h3> Stats 507 - Aggregation by Group </a>",
   "progress": true,
   "scroll": true,
   "theme": "solarized",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
