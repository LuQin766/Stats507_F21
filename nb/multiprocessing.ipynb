{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12534da3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Process-based Parallelism with Multiprocessing \n",
    "*Stats 507, Fall 2021*\n",
    "\n",
    "James Henderson, PhD  \n",
    "November 16, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b0eca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    " - [Parallel & Asynchronous Computing](#/slide-2-0)\n",
    " - [multiprocessing](#/slide-3-0)\n",
    " - [Pipes and Queues](#/slide-4-0)\n",
    " - [Pool](#/slide-5-0)\n",
    " - [Background Tasks](#/slide-6-0)\n",
    " - [asyncio](#/slide-7-0)\n",
    " - [Random Numbers](#/slide-8-0)\n",
    " - [Takeaways](#/slide-9-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61436b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MP Demo\n",
    "  - These slides are intended to be presented/read alongside the\n",
    "    `multiprocess` demo from the course repo. \n",
    "  - The demo relies on a number of functions defined in `cv_funcs.py`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18746914",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Computing in Data Science\n",
    "  - Many core data science methods are *trivially parallel* - composed of\n",
    "    a collection of independent tasks:\n",
    "    + Monte Carlo approximations,\n",
    "    + Bootstrap replication and other resampling methods,\n",
    "    + Cross-validation,\n",
    "    + Bagging estimators such as a random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488fca51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Built-in Parallelism\n",
    "  - A number of functions (e.g. sklearn estimators) have built-in support\n",
    "    for parallel computation:\n",
    "      + `LogisticRegressionCV()` using `n_jobs` parameter,\n",
    "      +  `RandomForestClassifier()` using `n_jobs` parameter.\n",
    "  - Prefer built-in methods when available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0f574",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Asynchronous Computing \n",
    " - [Asynchronous computing][async] refers to having events that occur \n",
    "    independently of the primary control flow in our program.  \n",
    " - In a traditional, *synchronous* program each statement or expression \n",
    "   *blocks* while evaluating -- it forces the program to wait until it \n",
    "   completes.\n",
    " - An *asynchronous* program has some statements that do not block -- allowing\n",
    "   the control flow to continue until either:\n",
    "    + the value of the non-blocking statement is needed, or\n",
    "    + execution resources such as CPU cores are exhausted.\n",
    "\n",
    "[async]:https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc8d9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Concurrent Programs for I/O bound tasks\n",
    " - Traditionally *concurrent* programming has been focused on I/O bound tasks.\n",
    " - If querying external servers or databases, would otherwise have to wait for \n",
    "   each query to finish and return before sending the next request.\n",
    " - Concurrency helps in this situation because it allows the program to wait \n",
    "   in multiple queues at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9a3d9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parallel Computing \n",
    " - Modern computers, including laptops and desktops, have multiple processors\n",
    "   or cores. \n",
    " - A parallel program takes advantage of this architecture to\n",
    "   complete more than one task at a time -- reducing the \"wall time\" a \n",
    "   *CPU-bound* program takes to run. \n",
    " - Concurrency including parallelism can be implemented using threads,\n",
    "   processes, futures or other abstractions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ff032",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parallelism is not Magic\n",
    " - When thinking of parallelizing some portion of a program, remember that \n",
    "   *parallelism is not magic*. \n",
    " - There is some computational overhead involved in splitting the task, \n",
    "   initializing child processes, communicating data, and collating results.  \n",
    " - For this reason, there is usually little to be gained in parallelizing \n",
    "   already fast computations.\n",
    " - An overly parallelized program incurs more *overhead* than necessary to \n",
    "   use available resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13b22a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Vectorization > Parallelism\n",
    " - Writing vectorized code is often more efficient than writing parallel code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b24864",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `multiprocessing`\n",
    "  - The built-in `multiprocessing` module provides *process-based parallelism*.\n",
    "  - Other modules in the standard library that support parallelism and \n",
    "    asynchronous computations include:\n",
    "     + `concurrent.futures`,\n",
    "     + `threading`,\n",
    "     + `asyncio`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ac016",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import cv_funcs as cvf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e9b03",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Process\n",
    "- Create a child process using `mp.Process()`. \n",
    "- The `Process` object's `.start()` method *spawns* a new Python process.\n",
    "- On Unix, can be started by forking (efficient).\n",
    "- A *forked* child process has *read-only* access to the objects in the \n",
    "  parent process's namespace. \n",
    "- On Windows or MacOS (recently) only the \"spawn\" option for an independent\n",
    "  process is supported. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16a407",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Process\n",
    "- The `target` argument is used to define a callable to be run when the \n",
    "  process has been initialized. \n",
    "- The `args` and `kwargs` parameters are used to pass arguments to the \n",
    "  callable passed to `target`. \n",
    "- A `Process` should be setup and started within a \"main gate\". \n",
    "- In an interactive session, local functions will not be recognized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569dafa4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Process\n",
    "- To block until a child process has completed, call its `.join()`\n",
    "  method.\n",
    "- This will also shutdown the child process.\n",
    "- Can call `.close()` method to shutdown zombie processes.  \n",
    "- Use `mp.active_children()` to see active child processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791eab33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipes and Queues\n",
    "> When using multiple processes, one generally uses *message passing* for \n",
    "> communication between processes and avoids having to use any synchronization\n",
    "> primitives like locks.\n",
    "\n",
    "> For passing messages one can use Pipe() (for a connection between \n",
    "> two processes) or a queue (which allows multiple producers and consumers).\n",
    "> \n",
    "> --[docs][pq]\n",
    "\n",
    "[pq]: https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c624aba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Queues\n",
    " - For *trivially parallel* tasks, use *queues* which easily generalize to \n",
    "   multiple processes.\n",
    " - A `Queue()` is implemented using a `Pipe()` but handles synchronization \n",
    "   implicitly. \n",
    " - Create a `Queue` using `mp.Queue()` with (optionally) a maximum size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b69d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Queues\n",
    "- *Producer* processes use a queue's `.put()` method to enter items into the\n",
    "  queue.\n",
    "- *Consumer* processes use a queue's `.get()` method to accept an item from \n",
    "  the queue.  \n",
    "- Both have optional `block` and `timeout` arguments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb9705",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Queue Pattern\n",
    " - We'll follow the pattern [here][mpq] which uses two queues:\n",
    "     + `task_queue` sends tasks from the parent process to child processes,\n",
    "     + `done_queue` sends results from the child processes to the parent \n",
    "        process.  \n",
    " - In this case, `task_queue` has a single *producer* and (potentially) \n",
    "   multiple *consumers*.\n",
    " - The `done_queue` has (potentially) multiple *producers* and a single\n",
    "   *consumer*. \n",
    "\n",
    " [mpq]: https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bf236",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Queue Pattern\n",
    " - In the pattern we'll use two key functions:\n",
    "   + `worker()` iterates over tasks in the queue until it receives the \n",
    "     *sentinel* to stop ('STOP');\n",
    "   + `calculate()` takes the tuple represent the task and calls the callable\n",
    "     with the unpacked arguments.\n",
    " - We encapsulate the full pattern into `mp_apply()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3addf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pool\n",
    " - A *pool* of worker processes can be setup with `mp.Pool()`. \n",
    " - The `Pool` object has several methods for dispatching work to these \n",
    "   child/worker processes.\n",
    " - The most straightforward is `.map()` which takes a function and an iterable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb60f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pool\n",
    " - A `Pool` object must be explicitly closed using `.close()` which will wait\n",
    "   for assigned processes to close.\n",
    " - A tidy way to ensure this implicitly is to use a `with` statement. \n",
    " - The `.join()` method can be used *after* `.close()` to block until all\n",
    "   tasks are completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372ccdc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Chunking\n",
    " - The `.map()` method accepts an argument `chunksize` to determine how \n",
    "   tasks are assigned to workers. \n",
    " - Larger chunks result in less communication overhead. \n",
    " - For tasks with predictable and low-variance run time, best to chunk so each\n",
    "   worker processes a single chunk. \n",
    " - For tasks with high-variance or long-tailed run times, better to use a \n",
    "   smaller chunk size to keep all workers busy for as long as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee3853",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Star maps\n",
    " - A `Pool` object's `.starmap()` method can be used to parallelize function\n",
    "   calls over more than one argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25120f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background task(s)\n",
    " - During model and notebook development, long-running tasks can interrupt\n",
    "   our flow by blocking the active process (kernel).\n",
    " - Running these tasks asynchronously (\"in the background\") using a\n",
    "   non-blocking workflow can help us to be more productive.\n",
    " - We implement this concept using the \"queue\" pattern in the functions\n",
    "   `bg_task()` and `bg_get()`.\n",
    " - See also `Pool.map_async()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceefc25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## asyncio\n",
    " - The asyncio is designed for writing concurrent I/O operations -- \n",
    "   particularly useful for working with websites.\n",
    " - There are three key concepts: \n",
    "    + Define asynchronous, non-blocking functions using `async def`.\n",
    "    + Block and retrieve results using `await`,\n",
    "    + Every asynchronous function call must be awaited.  \n",
    " - You can think of the \"coroutine\" as a value that will be available at some\n",
    "   point in the future.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1720965",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Background Tasks using asyncio\n",
    " - We implement the \"background tasks\" pattern using asyncio in `async_task()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da2018",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Numbers\n",
    " - Many statistical and machine learning applications rely on pseudo-random \n",
    "   numbers for things like  sampling from distributions and stochastic \n",
    "   optimization, e.g. bootstrap, Monte Carlo.\n",
    " - Care needs to be taken to ensure random number streams behave as expected \n",
    "   when using parallel computations.\n",
    " - Issues of both reproducibility and (pseudo)-independence. \n",
    " - Read more about this at \n",
    "   https://numpy.org/doc/stable/reference/random/parallel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50a5aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Takeaways\n",
    "  - Many data science methods can be trivially parallelized.   \n",
    "  - The multiprocessing module provides *process-based parallelism*. \n",
    "  - Reduce run-time by spreading computations across multiple Python sessions.\n",
    "  - Run long-running code in the background during development. \n",
    "  - Use built-in methods for parallel computing when available."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "rise"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "header": "<a href=\"#/slide-0-0\"> <h3> Stats 507 - Process Parallelism </a>",
   "progress": true,
   "scroll": true,
   "theme": "solarized",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
