{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef006112",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monte Carlo Studies\n",
    "*Stats 507, Fall 2021*\n",
    "\n",
    "James Henderson, PhD  \n",
    "October 5, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5563da2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    " - [Monte Carlo](#/slide-2-0)\n",
    " - [Example - Estimating pi](#/slide-3-0)\n",
    " - [LLN & CLT](#/slide-4-0)\n",
    " - [Precision](#/slide-7-0)\n",
    " - [Takeaways](#/slide-8-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9900f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monte Carlo - *Why* \n",
    " - In statistics and data science we are often interested in computing \n",
    "   expectations (means) of various types of random outcomes.\n",
    " - When analytic expectations are unavailable or cumbersome to compute, \n",
    "   it can be useful to obtain *Monte Carlo* approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e255d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monte Carlo - *What* \n",
    " - We form Monte Carlo estimates by simulating (from) a random process and\n",
    "   then directly averaging the values of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337d6ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    " - In this example, we'll from a Monte Carlo estimate of $\\pi.$ \n",
    " - Our estimate is based on the fact that the unit circle has area $\\pi.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d338fc",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "n_mc = 1000\n",
    "rng = np.random.default_rng(10 * 5 / 2021)\n",
    "xy = rng.random.uniform(2 * n_mc)\n",
    "xy = xy.reshape((2, n_mc))\n",
    "d = np.power(xy[0, :], 2) + np.power(xy[1, :], 2)\n",
    "p_hat = np.mean(d < 1)\n",
    "pi_hat = 4 * p_hat\n",
    "pi_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5eaa5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of Large Numbers\n",
    " - Monte Carlo estimation works because the sample average is generally a\n",
    "   good estimate of the corresponding expectation \n",
    "   $\\bar{\\theta}_n \\to_p \\theta $.\n",
    "$$\n",
    "{\\bar{\\theta}}_{n} := \\sum_{i=1}^n X_i / n  \\to_p \\theta := E[X].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7352bd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem\n",
    " - Assume our data are:\n",
    "   + *independent and identically distributed* (iid),\n",
    "   + from a distribution with finite variance.\n",
    " - Then, the rate of convergence of a sample average to its population \n",
    "   counterpart is characterized by the *central limit theorem* (CLT):\n",
    "$$\n",
    " \\sqrt{n}(\\bar{\\theta}_n - \\theta) \\to_{d} N(0,\\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1ed3f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Central Limit Theorem\n",
    " - On the previous slide, $\\sigma^2$ is the variance of\n",
    "   the underlying distribution from which X is drawn.\n",
    "\n",
    " - Estimate the variance of a Monte Carlo estimate to construct confidence\n",
    "   intervals around your estimates.\n",
    "\n",
    " - Choose the number of Monte Carlo replicates to attain the desired precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d223921",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "se = 4 * np.sqrt(p_hat * (1 - p_hat) / n_mc)\n",
    "\n",
    "se2 = 4 * np.sqrt( np.var(d) / n_mc )\n",
    "z = norm.ppf(.975)\n",
    "lwr, upr = pi_hat - z * se, pi_hat + z * se\n",
    "'{0:5.3f} ({1:4.2f}, {2:4.2f})'.format(pi_hat, lwr, upr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fc3ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Level\n",
    "- We chose $z = \\Phi^{-1}(0.975)$ on the previous slide to attain a 95% \n",
    "  *confidence level*. \n",
    "- This means that we expect the population parameter ($\\pi$) to be in our\n",
    "  (random) interval 95% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e053d6",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "lwr < np.pi < upr # Expect this to be True ~95% of the time with z = 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c532e",
   "metadata": {},
   "source": [
    "<!-- #endregion -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0122dd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Desired Precision\n",
    "- Suppose we need to estimate $\\pi$ to within $\\pm 0.001$ with 99% confidence.\n",
    "- To determine the number of Monte Carlo replicates we should use to attain\n",
    "  the desired margin of error, solve the inequality, \n",
    "  \n",
    "$$\n",
    "\\Phi^{-1}(0.995) 4 \\sqrt{ \\frac{\\pi}{4} \\left(1 - \\frac{\\pi}{4}\\right) / n }  \n",
    " < 0.001.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657ac13",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "z = norm.ppf(.995)\n",
    "n_min =  (1000 * z * 4 * np.sqrt(np.pi / 4 * (1 - np.pi / 4))) ** 2\n",
    "n_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e6f989",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "- Here is our earlier example with 18 million Monte Carlo replicates.\n",
    "- This is feasible because we are using vectorized operations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35767664",
   "metadata": {
    "slideshow": {
     "slide_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "n_mc = int(1.8e7)\n",
    "xy = rng.uniform(size=2 * n_mc).reshape((2, n_mc))\n",
    "d = np.power(xy[0, :], 2) + np.power(xy[1, :], 2)\n",
    "eps = 4 * np.mean(d < 1) - np.pi\n",
    "(eps, np.abs(eps) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0e8023",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Takeaways\n",
    "- *Monte Carlo* estimates are statistical estimates of population parameters\n",
    "  using \"data\" simulated from a (pseudo-)random process.\n",
    "- Use vectorized operations for efficient *Monte Carlo* estimation. \n",
    "- Use the CLT or the Normal approximation to the Binomial to estimate the \n",
    "  variance of a Monte Carlo estimate.\n",
    "- Choose the number of Monte Carlo replicates based on the required/desired\n",
    "  precision.  \n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "rise"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "header": "<a href=\"#/slide-0-0\"> <h3> Stats 507 - Monte Carlo Studies </a>",
   "progress": true,
   "scroll": true,
   "theme": "solarized",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
